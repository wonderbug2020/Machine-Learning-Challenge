{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data\n",
    "df = pd.read_csv('resources/exoplanet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in a data frame withthe desired features, preprocesses the data, makes, tests, and gives the score for a\n",
    "#Linear regression model. Really just did this to save a lot of copy pasta\n",
    "def log_reg_model(df):\n",
    "    feature_select = df\n",
    "    \n",
    "    #Remove the Candidate  rows\n",
    "    dataset = feature_select[feature_select['koi_disposition'] != 'CANDIDATE']\n",
    "    \n",
    "    #Create X and y\n",
    "    X = dataset.iloc[:,:-1].values\n",
    "    y = dataset.iloc[:,-1].values\n",
    "    \n",
    "    #Create Train-test split    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "    \n",
    "    #Standardize the data    \n",
    "    mms = MinMaxScaler()\n",
    "    X_train_mms = mms.fit_transform(X_train)\n",
    "    X_test_mms = mms.transform(X_test)\n",
    "    \n",
    "    #Using logistic regression, fit the model then make predictions from the test set\n",
    "    log_cla = LogisticRegression(random_state = 0)\n",
    "    log_cla.fit(X_train_mms, y_train)\n",
    "    log_pred = log_cla.predict(X_test_mms)\n",
    "    \n",
    "    #print the results\n",
    "    #print(\"###########\")\n",
    "    cm = confusion_matrix(y_test, log_pred)\n",
    "    print(cm)\n",
    "    score = accuracy_score(y_test, log_pred)\n",
    "    print(score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since I've singled out one of these 4 columns to have potential colinearity issues, so this represents all possible combinations\n",
    "#Singles\n",
    "feature_select_nt = df[['koi_fpflag_nt', 'koi_disposition']]#1\n",
    "feature_select_ss = df[['koi_fpflag_ss', 'koi_disposition']]#2\n",
    "feature_select_co = df[['koi_fpflag_co', 'koi_disposition']]#3\n",
    "feature_select_ec = df[['koi_fpflag_ec', 'koi_disposition']]#4\n",
    "#Doubles\n",
    "feature_select_nt_ss = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_disposition']]#5\n",
    "feature_select_nt_co = df[['koi_fpflag_nt', 'koi_fpflag_co', 'koi_disposition']]#6\n",
    "feature_select_nt_ec = df[['koi_fpflag_nt', 'koi_fpflag_ec', 'koi_disposition']]#7\n",
    "feature_select_ss_co = df[['koi_fpflag_ss', 'koi_fpflag_co', 'koi_disposition']]#8\n",
    "feature_select_ss_ec = df[['koi_fpflag_ss', 'koi_fpflag_ec', 'koi_disposition']]#9\n",
    "feature_select_co_ec = df[['koi_fpflag_co', 'koi_fpflag_ec', 'koi_disposition']]#10\n",
    "#Triples\n",
    "feature_select_nt_ss_co = df[['koi_fpflag_nt', 'koi_fpflag_ss','koi_fpflag_co', 'koi_disposition']]#11\n",
    "feature_select_nt_ss_ec = df[['koi_fpflag_nt', 'koi_fpflag_ss','koi_fpflag_ec', 'koi_disposition']]#12\n",
    "feature_select_nt_co_ec = df[['koi_fpflag_nt', 'koi_fpflag_co','koi_fpflag_ec', 'koi_disposition']]#13\n",
    "feature_select_ss_co_ec = df[['koi_fpflag_ss', 'koi_fpflag_co','koi_fpflag_ec', 'koi_disposition']]#14\n",
    "#All 4\n",
    "feature_select_ful = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec', 'koi_disposition']]#15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I put all the combinations into a list so I could iterate through them\n",
    "df_lst = [feature_select_nt,feature_select_ss,feature_select_co,feature_select_ec,\n",
    "          feature_select_nt_ss,feature_select_nt_co,feature_select_nt_ec,\n",
    "          feature_select_ss_co,feature_select_ss_ec,\n",
    "          feature_select_co_ec,\n",
    "          feature_select_nt_ss_co,feature_select_nt_ss_ec,feature_select_nt_co_ec,feature_select_ss_co_ec,\n",
    "          feature_select_ful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[  0 447]\n",
      " [  0 879]]\n",
      "0.6628959276018099\n",
      "\n",
      "2\n",
      "[[  0 447]\n",
      " [  0 879]]\n",
      "0.6628959276018099\n",
      "\n",
      "3\n",
      "[[  0 447]\n",
      " [  0 879]]\n",
      "0.6628959276018099\n",
      "\n",
      "4\n",
      "[[  0 447]\n",
      " [  0 879]]\n",
      "0.6628959276018099\n",
      "\n",
      "5\n",
      "[[438   9]\n",
      " [199 680]]\n",
      "0.8431372549019608\n",
      "\n",
      "6\n",
      "[[440   7]\n",
      " [326 553]]\n",
      "0.748868778280543\n",
      "\n",
      "7\n",
      "[[442   5]\n",
      " [443 436]]\n",
      "0.6621417797888386\n",
      "\n",
      "8\n",
      "[[441   6]\n",
      " [238 641]]\n",
      "0.8159879336349924\n",
      "\n",
      "9\n",
      "[[443   4]\n",
      " [311 568]]\n",
      "0.7624434389140271\n",
      "\n",
      "10\n",
      "[[  0 447]\n",
      " [  0 879]]\n",
      "0.6628959276018099\n",
      "\n",
      "11\n",
      "[[436  11]\n",
      " [ 32 847]]\n",
      "0.9675716440422323\n",
      "\n",
      "12\n",
      "[[438   9]\n",
      " [ 95 784]]\n",
      "0.9215686274509803\n",
      "\n",
      "13\n",
      "[[440   7]\n",
      " [280 599]]\n",
      "0.7835595776772247\n",
      "\n",
      "14\n",
      "[[441   6]\n",
      " [189 690]]\n",
      "0.8529411764705882\n",
      "\n",
      "15\n",
      "[[436  11]\n",
      " [  0 879]]\n",
      "0.9917043740573153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For loop goes through all the combinations and runs them throug the model\n",
    "n = 1\n",
    "for ds in df_lst:\n",
    "    print(n)\n",
    "    log_reg_model(ds)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outside of all 4 being present, number 11 and 12 had high accuracy. THis leads me to believe there is high colinearity between\n",
    "#features koi_fpflag_nt and koi_fpflag_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
