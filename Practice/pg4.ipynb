{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data\n",
    "df = pd.read_csv('exoplanet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes in a data frame withthe desired features, preprocesses the data, makes, tests, and gives the score for a\n",
    "#Linear regression model. Really just did this to save a lot of copy pasta\n",
    "def log_reg_model(df):\n",
    "    feature_select = df\n",
    "    \n",
    "    #Remove the Candidate  rows\n",
    "    dataset = feature_select[feature_select['koi_disposition'] != 'CANDIDATE']\n",
    "    \n",
    "    #Create X and y\n",
    "    X = dataset.iloc[:,:-1].values\n",
    "    y = dataset.iloc[:,-1].values\n",
    "    \n",
    "    #Create Train-test split    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "    \n",
    "    #Standardize the data    \n",
    "    mms = MinMaxScaler()\n",
    "    X_train_mms = mms.fit_transform(X_train)\n",
    "    X_test_mms = mms.transform(X_test)\n",
    "    \n",
    "    #Using logistic regression, fit the model then make predictions from the test set\n",
    "    log_cla = LogisticRegression(random_state = 0)\n",
    "    log_cla.fit(X_train_mms, y_train)\n",
    "    log_pred = log_cla.predict(X_test_mms)\n",
    "    \n",
    "    #print the results\n",
    "    #print(\"###########\")\n",
    "    cm = confusion_matrix(y_test, log_pred)\n",
    "    print(cm)\n",
    "    score = accuracy_score(y_test, log_pred)\n",
    "    print(score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since I've singled out one of these 4 columns to have potential colinearity issues, so this represents all possible combinations\n",
    "#Singles\n",
    "feature_select_nt = df[['koi_fpflag_nt', 'koi_disposition']]#1\n",
    "feature_select_ss = df[['koi_fpflag_ss', 'koi_disposition']]#2\n",
    "feature_select_co = df[['koi_fpflag_co', 'koi_disposition']]#3\n",
    "feature_select_ec = df[['koi_fpflag_ec', 'koi_disposition']]#4\n",
    "#Doubles\n",
    "feature_select_nt_ss = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_disposition']]#5\n",
    "feature_select_nt_co = df[['koi_fpflag_nt', 'koi_fpflag_co', 'koi_disposition']]#6\n",
    "feature_select_nt_ec = df[['koi_fpflag_nt', 'koi_fpflag_ec', 'koi_disposition']]#7\n",
    "feature_select_ss_co = df[['koi_fpflag_ss', 'koi_fpflag_co', 'koi_disposition']]#8\n",
    "feature_select_ss_ec = df[['koi_fpflag_ss', 'koi_fpflag_ec', 'koi_disposition']]#9\n",
    "feature_select_co_ec = df[['koi_fpflag_co', 'koi_fpflag_ec', 'koi_disposition']]#10\n",
    "#Triples\n",
    "feature_select_nt_ss_co = df[['koi_fpflag_nt', 'koi_fpflag_ss','koi_fpflag_co', 'koi_disposition']]#11\n",
    "feature_select_nt_ss_ec = df[['koi_fpflag_nt', 'koi_fpflag_ss','koi_fpflag_ec', 'koi_disposition']]#12\n",
    "feature_select_nt_co_ec = df[['koi_fpflag_nt', 'koi_fpflag_co','koi_fpflag_ec', 'koi_disposition']]#13\n",
    "feature_select_ss_co_ec = df[['koi_fpflag_ss', 'koi_fpflag_co','koi_fpflag_ec', 'koi_disposition']]#14\n",
    "#All 4\n",
    "feature_select_ful = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec', 'koi_disposition']]#15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I put all the combinations into a list so I could iterate through them\n",
    "df_lst = [feature_select_nt,feature_select_ss,feature_select_co,feature_select_ec,\n",
    "          feature_select_nt_ss,feature_select_nt_co,feature_select_nt_ec,\n",
    "          feature_select_ss_co,feature_select_ss_ec,\n",
    "          feature_select_co_ec,\n",
    "          feature_select_nt_ss_co,feature_select_nt_ss_ec,feature_select_nt_co_ec,feature_select_ss_co_ec,\n",
    "          feature_select_ful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loop goes through all the combinations and runs them throug the model\n",
    "n = 1\n",
    "for ds in df_lst:\n",
    "    print(n)\n",
    "    log_reg_model(ds)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outside of all 4 being present, number 11 and 12 had high accuracy. THis leads me to believe there is high colinearity between\n",
    "#features koi_fpflag_nt and koi_fpflag_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
